{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "296326fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from patsy import dmatrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyearth import Earth\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7b6ed",
   "metadata": {},
   "source": [
    "# Q1 {-}\n",
    "Find the number of degrees of freedom of the followng models. Exclude the intercept when counting the degrees of freedom. You may either show your calculation, or explain briefly how you are computing the degrees of freedom.\n",
    "\n",
    "(a) A model with one predictor, where the predictor is transformed into a quadratic spline with 5 knots \\\n",
    "(b) A model with one predictor, where the predictor is transformed into a natural cubic spline with 4 knots \\\n",
    "(c) A model with four predictors, where the transformations of the respective predictors are (i) cubic spline transformation with 3 knots, (ii) log transformation, (iii) linear spline transformation with 2 knots, (iv) polynomial transformation of degree 4.\n",
    "\n",
    "*(2 + 2 + 6 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7731c",
   "metadata": {},
   "source": [
    "Computing the degrees of freedom:\n",
    "    \n",
    "    1. df = k + 2 = 5 +2 = 7\n",
    "   \n",
    "   2. df = k + 1 = 4 + 1 = 5\n",
    "   \n",
    "   3. \n",
    "        i. df = k + 3 = 6\n",
    "        \n",
    "        ii. df = 1 (log transformation)\n",
    "       \n",
    "       iii. df = k + 1 = 3\n",
    "       \n",
    "       iv. df = 4 (polynomial transformation with no knots)\n",
    "\n",
    "model with four predictors:\n",
    "        df = 6 + 1 + 3 + 4 = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e00821",
   "metadata": {},
   "source": [
    "# Q2 {-}\n",
    "Find the number of knots in the following spline transformations, if each transformation corresponds to 7 degrees of freedom (excluding the intercept).\n",
    "\n",
    "(a) Cubic spline transformation \\\n",
    "(b) Natural cubic spline transformation \\\n",
    "(c) Spline transformation of degree 4\n",
    "\n",
    "*(3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607b996",
   "metadata": {},
   "source": [
    "a. cubic spline transformation has 4 knots\n",
    "\n",
    "b. natural cubic spline transformation has 2 knots\n",
    "\n",
    "c. spline transformaition of degree 4 has 3 knots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ffd7a",
   "metadata": {},
   "source": [
    "# Q3 {-}\n",
    "Read the datasets *house_feature_train.csv, house_price_train.csv, house_feature_test.csv* and *house_price_test.csv*. Develop a generalized additive model (GAM) to predict *house_price* based on all the predictors except *house_id*. Use the following transformations:\n",
    "\n",
    "(a) Log transformation of *house_price* \\\n",
    "(b) Natural cubic spline transformation of *house_age* with 4 degrees of freedom \\\n",
    "(c) Log transformation of *distance_MRT* \\\n",
    "(d) Natural cubic spline transformation of *number_convenience_stores* with 4 degrees of freedom \\\n",
    "\n",
    "Use no transformations for *latitude* and *longitude*. Use the datasets with the *'_train'* suffix to develop the model.\n",
    "\n",
    "What is the adjusted R-squared of the developed model?\n",
    "\n",
    "*(4 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84dda309",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_train = pd.read_csv(\"house_price_train.csv\")\n",
    "price_test = pd.read_csv(\"house_price_test.csv\")\n",
    "feature_train = pd.read_csv(\"house_feature_train.csv\")\n",
    "feature_test = pd.read_csv(\"house_feature_test.csv\")\n",
    "\n",
    "train = pd.merge(price_train, feature_train)\n",
    "test = pd.merge(price_test, feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfebb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(train[\"house_price\"])\n",
    "\n",
    "transformed_x = dmatrix(\"cr(house_age, df = 4, constraints = 'center') + np.log(distance_MRT) + cr(number_convenience_stores, df = 4, constraints = 'center') + longitude + latitude\",\n",
    "                        data = {'house_age':train['house_age'], 'distance_MRT':train['distance_MRT'], 'number_convenience_stores':train['number_convenience_stores'], 'longitude':train['longitude'], 'latitude':train['latitude']},return_type = 'dataframe')\n",
    "\n",
    "model = sm.OLS(y, transformed_x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af622e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>house_price</td>   <th>  R-squared:         </th> <td>   0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   115.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>6.59e-94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:33:35</td>     <th>  Log-Likelihood:    </th> <td> -79.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   275</td>      <th>  AIC:               </th> <td>   182.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   263</td>      <th>  BIC:               </th> <td>   225.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                <td></td>                                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                    <td>-1102.5466</td> <td>  211.858</td> <td>   -5.204</td> <td> 0.000</td> <td>-1519.700</td> <td> -685.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(house_age, df=4, constraints='center')[0]</th>                 <td>   -0.1271</td> <td>    0.061</td> <td>   -2.093</td> <td> 0.037</td> <td>   -0.247</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(house_age, df=4, constraints='center')[1]</th>                 <td>   -0.2812</td> <td>    0.049</td> <td>   -5.758</td> <td> 0.000</td> <td>   -0.377</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(house_age, df=4, constraints='center')[2]</th>                 <td>   -0.3542</td> <td>    0.059</td> <td>   -5.988</td> <td> 0.000</td> <td>   -0.471</td> <td>   -0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(house_age, df=4, constraints='center')[3]</th>                 <td>    0.1912</td> <td>    0.125</td> <td>    1.529</td> <td> 0.128</td> <td>   -0.055</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(distance_MRT)</th>                                         <td>   -0.3048</td> <td>    0.032</td> <td>   -9.534</td> <td> 0.000</td> <td>   -0.368</td> <td>   -0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(number_convenience_stores, df=4, constraints='center')[0]</th> <td>   -0.0034</td> <td>    0.053</td> <td>   -0.064</td> <td> 0.949</td> <td>   -0.108</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(number_convenience_stores, df=4, constraints='center')[1]</th> <td>    0.1901</td> <td>    0.047</td> <td>    4.073</td> <td> 0.000</td> <td>    0.098</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(number_convenience_stores, df=4, constraints='center')[2]</th> <td>    0.1460</td> <td>    0.061</td> <td>    2.404</td> <td> 0.017</td> <td>    0.026</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cr(number_convenience_stores, df=4, constraints='center')[3]</th> <td>    0.1014</td> <td>    0.109</td> <td>    0.929</td> <td> 0.354</td> <td>   -0.114</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>longitude</th>                                                    <td>    4.5247</td> <td>    1.769</td> <td>    2.557</td> <td> 0.011</td> <td>    1.041</td> <td>    8.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latitude</th>                                                     <td>   22.4979</td> <td>    2.027</td> <td>   11.098</td> <td> 0.000</td> <td>   18.506</td> <td>   26.489</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.942</td> <th>  Durbin-Watson:     </th> <td>   2.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.230</td> <th>  Jarque-Bera (JB):  </th> <td>   2.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.185</td> <th>  Prob(JB):          </th> <td>   0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.305</td> <th>  Cond. No.          </th> <td>1.32e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.32e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            house_price   R-squared:                       0.828\n",
       "Model:                            OLS   Adj. R-squared:                  0.821\n",
       "Method:                 Least Squares   F-statistic:                     115.5\n",
       "Date:                Wed, 13 Apr 2022   Prob (F-statistic):           6.59e-94\n",
       "Time:                        22:33:35   Log-Likelihood:                -79.132\n",
       "No. Observations:                 275   AIC:                             182.3\n",
       "Df Residuals:                     263   BIC:                             225.7\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================================================================\n",
       "                                                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                    -1102.5466    211.858     -5.204      0.000   -1519.700    -685.393\n",
       "cr(house_age, df=4, constraints='center')[0]                    -0.1271      0.061     -2.093      0.037      -0.247      -0.008\n",
       "cr(house_age, df=4, constraints='center')[1]                    -0.2812      0.049     -5.758      0.000      -0.377      -0.185\n",
       "cr(house_age, df=4, constraints='center')[2]                    -0.3542      0.059     -5.988      0.000      -0.471      -0.238\n",
       "cr(house_age, df=4, constraints='center')[3]                     0.1912      0.125      1.529      0.128      -0.055       0.438\n",
       "np.log(distance_MRT)                                            -0.3048      0.032     -9.534      0.000      -0.368      -0.242\n",
       "cr(number_convenience_stores, df=4, constraints='center')[0]    -0.0034      0.053     -0.064      0.949      -0.108       0.101\n",
       "cr(number_convenience_stores, df=4, constraints='center')[1]     0.1901      0.047      4.073      0.000       0.098       0.282\n",
       "cr(number_convenience_stores, df=4, constraints='center')[2]     0.1460      0.061      2.404      0.017       0.026       0.266\n",
       "cr(number_convenience_stores, df=4, constraints='center')[3]     0.1014      0.109      0.929      0.354      -0.114       0.316\n",
       "longitude                                                        4.5247      1.769      2.557      0.011       1.041       8.008\n",
       "latitude                                                        22.4979      2.027     11.098      0.000      18.506      26.489\n",
       "==============================================================================\n",
       "Omnibus:                        2.942   Durbin-Watson:                   2.131\n",
       "Prob(Omnibus):                  0.230   Jarque-Bera (JB):                2.635\n",
       "Skew:                          -0.185   Prob(JB):                        0.268\n",
       "Kurtosis:                       3.305   Cond. No.                     1.32e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.32e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbfa39",
   "metadata": {},
   "source": [
    "**The adjusted r-squared for this developed model is 0.821.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce0a78",
   "metadata": {},
   "source": [
    "# Q4 {-}\n",
    "Find the RMSE of the model developed in the previous question on the test data (datasets with the *'_test'* suffix). Assume all variables in the *train* and *test* datasets have the same distribution.\n",
    "\n",
    "*(3 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1050a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dmatrix(\"cr(house_age, df = 4, constraints = 'center') + np.log(distance_MRT) + cr(number_convenience_stores, df = 4, constraints = 'center') + longitude + latitude\",\n",
    "                        data = {'house_age':test['house_age'], 'distance_MRT':test['distance_MRT'], 'number_convenience_stores':test['number_convenience_stores'], 'longitude':test['longitude'], 'latitude':test['latitude']},return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7512f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367.1329627411743"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(np.exp(model.predict(test_x)), test.house_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630059eb",
   "metadata": {},
   "source": [
    "**The RMSE of the model developed is 367.13.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381532db",
   "metadata": {},
   "source": [
    "# Q5 {-}\n",
    "Use 5-fold cross validation to optimize the degrees of freedom of the natural cubic spline transformations of *house_age* and *number_convenience_stores* in the model developed in Q3. Report the optimal degrees of freedom corresponding to both the predictors.\n",
    "\n",
    "Use the *sklearn* functions for 5-fold cross validation. Here is a good example of *K*-fold cross validation using *sklearn*: https://www.statology.org/k-fold-cross-validation-in-python/ \n",
    "\n",
    "**Hint**: Consider degrees of freedom ranging from 2 to 10 for the spline transformation of each of the two predictors -  *house_age* and *number_convenience_stores*\n",
    "\n",
    "*(7 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9388fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(train['house_price'])\n",
    "cv_score = {}\n",
    "for i in range(2,11):\n",
    "    for j in range(2, 11):\n",
    "        tranformed_x = dmatrix(f\"cr(house_age, df = {i}, constraints = 'center')+np.log(distance_MRT)+cr(number_convenience_stores, df = {j}, constraints = 'center')+latitude+longitude\",\n",
    "                               data = {'house_age': train['house_age'], 'distance_MRT': train['distance_MRT'], 'number_convenience_stores': train['number_convenience_stores'], 'latitude': train['latitude'], 'longitude': train['longitude']},\n",
    "                               return_type = 'dataframe')\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True) \n",
    "        model = LinearRegression()\n",
    "        scores = cross_val_score(model, transformed_x, y, scoring='neg_mean_squared_error',\n",
    "                                 cv=cv, n_jobs=-1)\n",
    "        cv_score[i,j] = np.mean(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f246b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2   2     0.116707\n",
       "8   5     0.116707\n",
       "    4     0.116707\n",
       "    3     0.116707\n",
       "    2     0.116707\n",
       "            ...   \n",
       "4   7     0.116707\n",
       "    6     0.116707\n",
       "    5     0.116707\n",
       "6   5     0.116707\n",
       "10  10    0.116707\n",
       "Length: 81, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo = pd.Series(cv_score)\n",
    "combo.sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d15222",
   "metadata": {},
   "source": [
    "**As you can see above, the most optimal df's are 2 degrees of freedom for both house_age and number_convenience_stores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b7a5b",
   "metadata": {},
   "source": [
    "# Q6 {-}\n",
    "Find the RMSE on test data, based on the optimized model developed in Q6. Assume all variables in the *train* and *test* datasets have the same distribution.\n",
    "\n",
    "*(4 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2914daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353.71403196764595"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_x = dmatrix(\"cr(house_age, df = 2, constraints = 'center') + np.log(distance_MRT) + cr(number_convenience_stores, df = 2, constraints = 'center') + longitude + latitude\",\n",
    "                        data = {'house_age':train['house_age'], 'distance_MRT':train['distance_MRT'], 'number_convenience_stores':train['number_convenience_stores'], 'longitude':train['longitude'], 'latitude':train['latitude']},return_type = 'dataframe')\n",
    "\n",
    "model = sm.OLS(y, transformed_x).fit()\n",
    "\n",
    "test_x = dmatrix(\"cr(house_age, df = 2, constraints = 'center') + np.log(distance_MRT) + cr(number_convenience_stores, df = 2, constraints = 'center') + longitude + latitude\",\n",
    "                        data = {'house_age':test['house_age'], 'distance_MRT':test['distance_MRT'], 'number_convenience_stores':test['number_convenience_stores'], 'longitude':test['longitude'], 'latitude':test['latitude']},return_type = 'dataframe')\n",
    "\n",
    "np.sqrt(mean_squared_error(np.exp(model.predict(test_x)), test.house_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34592ee8",
   "metadata": {},
   "source": [
    "**The RMSE is 353.71.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0c386",
   "metadata": {},
   "source": [
    "# Q7 {-}\n",
    "Develop a MARS (Multivariate adaptive regression spline) model to predict *house_price* based on all the predictors except *house_id*. Allow a maximum of two degree interaction. Use the datasets with the *'_train'* suffix to develop the model. Do not transform any predictors. What is the RMSE of the model on test data?\n",
    "\n",
    "*(4 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "faec79cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvsim\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:813: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "C:\\Users\\nvsim\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:1066: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "388.9160524789007"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns =[ 'house_price', 'house_id'])\n",
    "y = train['house_price']\n",
    "\n",
    "earth_model = Earth(max_terms = 500, max_degree = 2)\n",
    "earth_model.fit(X, y)\n",
    "np.sqrt(mean_squared_error(earth_model.predict(test.drop(columns = ['house_price', 'house_id'])), test.house_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e6a60",
   "metadata": {},
   "source": [
    "**The RMSE is 388.916.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e4b4b4",
   "metadata": {},
   "source": [
    "# Q8 {-} \n",
    "Update the MARS model in Q7 to obtain a RMSE of less than 325 units on test data. \\\n",
    "**Hint:** Log transform *house_price*, and optimize the degree of the model\n",
    "\n",
    "*(2 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd62e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvsim\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:813: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "C:\\Users\\nvsim\\anaconda3\\lib\\site-packages\\pyearth\\earth.py:1066: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "332.69332017786934"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['house_price','house_id'])\n",
    "y = np.log(train['house_price'])\n",
    "\n",
    "earth_model = Earth(max_terms = 500, max_degree = 1)\n",
    "earth_model.fit(X, y)\n",
    "np.sqrt(mean_squared_error(np.exp(earth_model.predict(test.drop(columns = ['house_price','house_id']))), test.house_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb55ab4",
   "metadata": {},
   "source": [
    "The RMSE for the MARS mode  is 332."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf57147",
   "metadata": {},
   "source": [
    "# Q9 {-}\n",
    "Which predictors are rejected by the model developed in Q8?\n",
    "\n",
    "*(1 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f72c4aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Model\n",
      "-------------------------------------------------\n",
      "Basis Function             Pruned  Coefficient   \n",
      "-------------------------------------------------\n",
      "(Intercept)                No      6.33144       \n",
      "h(distance_MRT-1144.44)    No      -0.000177672  \n",
      "h(1144.44-distance_MRT)    No      0.00078818    \n",
      "latitude                   Yes     None          \n",
      "h(house_age-27.6)          No      0.0307957     \n",
      "h(27.6-house_age)          No      0.0254309     \n",
      "number_convenience_stores  No      0.0299533     \n",
      "h(latitude-24.9702)        No      24.1518       \n",
      "h(24.9702-latitude)        No      -15.4567      \n",
      "h(latitude-24.9784)        Yes     None          \n",
      "h(24.9784-latitude)        Yes     None          \n",
      "h(latitude-24.9556)        Yes     None          \n",
      "h(24.9556-latitude)        Yes     None          \n",
      "-------------------------------------------------\n",
      "MSE: 0.1040, GCV: 0.1196, RSQ: 0.8285, GRSQ: 0.8044\n"
     ]
    }
   ],
   "source": [
    "print(earth_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55145359",
   "metadata": {},
   "source": [
    "**It pruned latitude and longitude.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43286849",
   "metadata": {},
   "source": [
    "# Q10 {-}\n",
    "The data for this question is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls, where bank clients were called to subscribe for a term deposit. \n",
    "\n",
    "There is one train data - *train.csv*, which you will use to develop a model. There are two test datasets - *test1.csv* and *test2.csv*, which you will use to test your model. Each dataset has the following attributes about the clients called in the marketing campaign:\n",
    "\n",
    "1) *age*: Age of the client\\\n",
    "2) *education*: Education level of the client \\\n",
    "3) *day*: Day of the month the call is made\\\n",
    "4) *month*: Month of the call \\\n",
    "5) *y*: did the client subscribe to a term deposit? \\\n",
    "6) *duration*: Call duration, in seconds. This attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call *y* is obviously known. Thus, this input should only be included for inference purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "(Raw data source: [Source](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Do not use the raw data source for this assingment. It is just for reference.)\n",
    "\n",
    "Develop a **generalized additive model (GAM)** to predict the probability of a client subscribing to a term deposit based on *age, education, day* and *month*. The model must have: \\\n",
    "(a)  **Minimum overall classification accuracy of 75%** among the classifcation accuracies on *train.csv*, *test1.csv* and *test2.csv*. \\\n",
    "(b) **Maximum false negative rate of 45%** among the false negative rates on *train.csv*, *test1.csv* and *test2.csv*. \n",
    "\n",
    "Print the confusion matrices for all the three datasets - *train.csv*, *test1.csv* and *test2.csv*, along with the overall classification accuracies, and false negative rates.\n",
    "\n",
    "\n",
    "Note that: \\\n",
    "(i) You cannot use *duration* as a predictor. The predictor is not useful for prediction because its value is determined after the marketing call ends. However, after the call ends, we already know whether the client responded positively or negatively. That is why we have used *duration* only for inference in the previous questions. It helped us understand the effect of the length of the call on marketing success. \\\n",
    "(ii) One way to develop the model satisfying constrains (a) and (b) is to use **spline tranformations for *age* and *day*, and interacting *month* with all the predictors (including the spline transformations)**\\\n",
    "(iii) You are free to choose any value of thershold probability for classifying observations. However, you must use the same threshold on all the three datasets.\n",
    "\n",
    "*(10 points for code)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
