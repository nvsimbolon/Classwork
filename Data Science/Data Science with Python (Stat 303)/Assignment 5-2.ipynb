{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee2b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457683a3",
   "metadata": {},
   "source": [
    "# Part 2 {-}\n",
    "See https://exoplanetarchive.ipac.caltech.edu (for context/source). We are using the Composite Planetary Systems dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf85da",
   "metadata": {},
   "source": [
    "# Q2a {-}\n",
    "Say we’re interested in modeling the radius of exoplanets in kilometers, which is named as `pl_rade` in the data. Note that the variable `pl_rade` captures the radius of each plant as a proportion of Earth’s radius, which is approximately 6,378.1370 km. \n",
    "\n",
    "Develop a linear regression model to predict `pl_rade` using all the variables in *train_CompositePlanetarySystems.csv* except `pl_name`, `disc_facility` and `disc_locale`. Find the RMSE (Root mean squared error) of the model on *test1_CompositePlanetarySystems.csv* and *test2_CompositePlanetarySystems.csv*. \n",
    "\n",
    "*(4 points for code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f94a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data\n",
    "train = pd.read_csv('train_CompositePlanetarySystems.csv')\n",
    "test1 = pd.read_csv('test1_CompositePlanetarySystems.csv')\n",
    "test2 = pd.read_csv('test2_CompositePlanetarySystems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cea58cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>pl_rade</td>     <th>  R-squared:         </th> <td>   0.724</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.719</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   124.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>4.83e-249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:43:16</td>     <th>  Log-Likelihood:    </th> <td> -2358.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   970</td>      <th>  AIC:               </th> <td>   4760.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   949</td>      <th>  BIC:               </th> <td>   4862.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>  370.5206</td> <td>   48.434</td> <td>    7.650</td> <td> 0.000</td> <td>  275.470</td> <td>  465.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sy_snum</th>         <td>    0.0252</td> <td>    0.297</td> <td>    0.085</td> <td> 0.932</td> <td>   -0.558</td> <td>    0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sy_pnum</th>         <td>   -0.7530</td> <td>    0.082</td> <td>   -9.157</td> <td> 0.000</td> <td>   -0.914</td> <td>   -0.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cb_flag</th>         <td>   -1.9300</td> <td>    2.001</td> <td>   -0.964</td> <td> 0.335</td> <td>   -5.857</td> <td>    1.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disc_year</th>       <td>   -0.1781</td> <td>    0.024</td> <td>   -7.480</td> <td> 0.000</td> <td>   -0.225</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rv_flag</th>         <td>    7.2423</td> <td>    0.265</td> <td>   27.343</td> <td> 0.000</td> <td>    6.722</td> <td>    7.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pul_flag</th>        <td>-1.086e-09</td> <td> 2.46e-10</td> <td>   -4.411</td> <td> 0.000</td> <td>-1.57e-09</td> <td>-6.03e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptv_flag</th>        <td>    3.5059</td> <td>    4.501</td> <td>    0.779</td> <td> 0.436</td> <td>   -5.327</td> <td>   12.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tran_flag</th>       <td>    1.1365</td> <td>    0.352</td> <td>    3.232</td> <td> 0.001</td> <td>    0.446</td> <td>    1.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ast_flag</th>        <td>    1.5613</td> <td>    2.059</td> <td>    0.758</td> <td> 0.448</td> <td>   -2.479</td> <td>    5.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>obm_flag</th>        <td>   -0.9951</td> <td>    1.149</td> <td>   -0.866</td> <td> 0.387</td> <td>   -3.250</td> <td>    1.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>micro_flag</th>      <td> 1.405e-11</td> <td> 3.18e-12</td> <td>    4.417</td> <td> 0.000</td> <td> 7.81e-12</td> <td> 2.03e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>etv_flag</th>        <td>    4.0156</td> <td>    5.375</td> <td>    0.747</td> <td> 0.455</td> <td>   -6.533</td> <td>   14.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ima_flag</th>        <td>-2362.1345</td> <td>  540.655</td> <td>   -4.369</td> <td> 0.000</td> <td>-3423.151</td> <td>-1301.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pl_controv_flag</th> <td>   -4.4229</td> <td>    2.569</td> <td>   -1.722</td> <td> 0.085</td> <td>   -9.464</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pl_orbper</th>       <td>    0.0003</td> <td> 6.73e-05</td> <td>    4.404</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pl_dens</th>         <td>   -0.0088</td> <td>    0.009</td> <td>   -0.964</td> <td> 0.335</td> <td>   -0.027</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ttv_flag</th>        <td>    0.8794</td> <td>    0.362</td> <td>    2.432</td> <td> 0.015</td> <td>    0.170</td> <td>    1.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>st_teff</th>         <td>    0.0005</td> <td>    0.000</td> <td>    2.860</td> <td> 0.004</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>st_rad</th>          <td>   -0.1803</td> <td>    0.057</td> <td>   -3.182</td> <td> 0.002</td> <td>   -0.291</td> <td>   -0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>st_mass</th>         <td>    3.3632</td> <td>    0.580</td> <td>    5.803</td> <td> 0.000</td> <td>    2.226</td> <td>    4.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>st_lum</th>          <td>   -1.1531</td> <td>    0.448</td> <td>   -2.572</td> <td> 0.010</td> <td>   -2.033</td> <td>   -0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>st_logg</th>         <td>   -3.2476</td> <td>    0.677</td> <td>   -4.796</td> <td> 0.000</td> <td>   -4.576</td> <td>   -1.919</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>45.899</td> <th>  Durbin-Watson:     </th> <td>   1.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 141.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.088</td> <th>  Prob(JB):          </th> <td>1.83e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.863</td> <th>  Cond. No.          </th> <td>8.64e+23</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.66e-35. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                pl_rade   R-squared:                       0.724\n",
       "Model:                            OLS   Adj. R-squared:                  0.719\n",
       "Method:                 Least Squares   F-statistic:                     124.8\n",
       "Date:                Mon, 07 Mar 2022   Prob (F-statistic):          4.83e-249\n",
       "Time:                        21:43:16   Log-Likelihood:                -2358.9\n",
       "No. Observations:                 970   AIC:                             4760.\n",
       "Df Residuals:                     949   BIC:                             4862.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept         370.5206     48.434      7.650      0.000     275.470     465.572\n",
       "sy_snum             0.0252      0.297      0.085      0.932      -0.558       0.608\n",
       "sy_pnum            -0.7530      0.082     -9.157      0.000      -0.914      -0.592\n",
       "cb_flag            -1.9300      2.001     -0.964      0.335      -5.857       1.997\n",
       "disc_year          -0.1781      0.024     -7.480      0.000      -0.225      -0.131\n",
       "rv_flag             7.2423      0.265     27.343      0.000       6.722       7.762\n",
       "pul_flag        -1.086e-09   2.46e-10     -4.411      0.000   -1.57e-09   -6.03e-10\n",
       "ptv_flag            3.5059      4.501      0.779      0.436      -5.327      12.339\n",
       "tran_flag           1.1365      0.352      3.232      0.001       0.446       1.827\n",
       "ast_flag            1.5613      2.059      0.758      0.448      -2.479       5.601\n",
       "obm_flag           -0.9951      1.149     -0.866      0.387      -3.250       1.260\n",
       "micro_flag       1.405e-11   3.18e-12      4.417      0.000    7.81e-12    2.03e-11\n",
       "etv_flag            4.0156      5.375      0.747      0.455      -6.533      14.564\n",
       "ima_flag        -2362.1345    540.655     -4.369      0.000   -3423.151   -1301.118\n",
       "pl_controv_flag    -4.4229      2.569     -1.722      0.085      -9.464       0.618\n",
       "pl_orbper           0.0003   6.73e-05      4.404      0.000       0.000       0.000\n",
       "pl_dens            -0.0088      0.009     -0.964      0.335      -0.027       0.009\n",
       "ttv_flag            0.8794      0.362      2.432      0.015       0.170       1.589\n",
       "st_teff             0.0005      0.000      2.860      0.004       0.000       0.001\n",
       "st_rad             -0.1803      0.057     -3.182      0.002      -0.291      -0.069\n",
       "st_mass             3.3632      0.580      5.803      0.000       2.226       4.501\n",
       "st_lum             -1.1531      0.448     -2.572      0.010      -2.033      -0.273\n",
       "st_logg            -3.2476      0.677     -4.796      0.000      -4.576      -1.919\n",
       "==============================================================================\n",
       "Omnibus:                       45.899   Durbin-Watson:                   1.928\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              141.548\n",
       "Skew:                           0.088   Prob(JB):                     1.83e-31\n",
       "Kurtosis:                       4.863   Cond. No.                     8.64e+23\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.66e-35. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "predictors = '+'.join(list(train.drop(columns = ['pl_name', 'disc_facility', 'disc_locale', 'pl_rade']).columns))\n",
    "model = sm.ols('pl_rade~'+predictors, data = train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d2c8fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for test 1 is 127.36595496362591. The RMSE for test 2 is 202.66277572552613\n"
     ]
    }
   ],
   "source": [
    "rmse1 = np.sqrt(((test1.pl_rade - model.predict(test1))**2).mean())\n",
    "rmse2 = np.sqrt(((test2.pl_rade - model.predict(test2))**2).mean())\n",
    "print(f'The RMSE for test 1 is {rmse1}. The RMSE for test 2 is {rmse2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2322e",
   "metadata": {},
   "source": [
    "# Q2b {-}\n",
    "Develop a ridge regression model to predict `pl_rade` using all the variables in *train_CompositePlanetarySystems.csv* except `pl_name`, `disc_facility` and `disc_locale`. What is the optimal value of the tuning parameter $\\lambda$?\n",
    "\n",
    "**Hint:** You may use the following grid of lambda values to find the optimal $\\lambda$: \n",
    "`alphas = 10**np.linspace(2,0.5,200)*0.5`\n",
    "\n",
    "Remember to standardize data before fitting the ridge regression model\n",
    "\n",
    "\n",
    "*(5 points for code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac9c72f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.221181754360687"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "y = train['pl_rade']\n",
    "X = train.drop(columns = ['pl_name', 'disc_facility', 'disc_locale', 'pl_rade'])\n",
    "scaler.fit(X)\n",
    "Xstd = scaler.transform(X)\n",
    "\n",
    "# Tuning Parameters\n",
    "alphas = 10**np.linspace(2,0.5,200)*0.5\n",
    "\n",
    "# Ridge: Finding Optimal lambda\n",
    "ridgecv = RidgeCV(alphas = alphas,store_cv_values=True)\n",
    "ridgecv.fit(Xstd, y)\n",
    "\n",
    "#Optimal value of the tuning parameter - lamda\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fc1de",
   "metadata": {},
   "source": [
    "# Q2c {-}\n",
    "Use the optimal value of $\\lambda$ found in the previous question to develop a ridge regression model. What is the RMSE of the model on *test1_CompositePlanetarySystems.csv* and *test2_CompositePlanetarySystems.csv*?\n",
    "\n",
    "*(5 points for code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b562b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1 RMSE: 3.2187088791485707\n",
      "test 2 RMSE: 2.989865167853597\n"
     ]
    }
   ],
   "source": [
    "#Standardizing tests\n",
    "X_test1 = test1.drop(columns = ['pl_name', 'disc_facility', 'disc_locale', 'pl_rade'])\n",
    "X_test2 = test2.drop(columns = ['pl_name', 'disc_facility', 'disc_locale', 'pl_rade'])\n",
    "Xtest1_std = scaler.transform(X_test1)\n",
    "Xtest2_std = scaler.transform(X_test2)\n",
    "\n",
    "ridge = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge.fit(Xstd, y)\n",
    "pred = ridge.predict(Xtest1_std)\n",
    "rmse_1 = np.sqrt(((pred - test1.pl_rade)**2).mean())\n",
    "print('test 1 RMSE:', rmse_1)\n",
    "\n",
    "pred=ridge.predict(Xtest2_std)\n",
    "rmse_2 = np.sqrt(((pred - test2.pl_rade)**2).mean())\n",
    "print('test 2 RMSE:', rmse_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e6acf",
   "metadata": {},
   "source": [
    "# Q2d {-}\n",
    "Note that ridge regression has a much lower RMSE on test datasets as compared to Ordinary least squares (OLS) regression. Shrinking the coefficients has improved the model fit. Appreciate it. Which are the top two predictors for which the coefficients have shrunk the most? \n",
    "\n",
    "To answer this question, find the ridge regression estimates for $\\lambda = 10^{-10}$. Treat these estimates as OLS estimates and find the predictors for which these estimates have shrunk the most in the model developed in 2c.\n",
    "\n",
    "*(4 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea283f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ima_flag          -75.804463\n",
       "st_logg            -1.383991\n",
       "sy_pnum            -0.876263\n",
       "st_lum             -0.812958\n",
       "disc_year          -0.780497\n",
       "st_rad             -0.513427\n",
       "pl_controv_flag    -0.200628\n",
       "cb_flag            -0.123682\n",
       "pl_dens            -0.086940\n",
       "obm_flag           -0.084228\n",
       "micro_flag          0.000000\n",
       "pul_flag            0.000000\n",
       "sy_snum             0.008191\n",
       "ast_flag            0.070820\n",
       "ptv_flag            0.112509\n",
       "etv_flag            0.182152\n",
       "ttv_flag            0.229052\n",
       "tran_flag           0.453724\n",
       "st_teff             0.954692\n",
       "st_mass             1.055440\n",
       "rv_flag             3.469238\n",
       "pl_orbper          76.418631\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_lambda = Ridge(alpha = 10**(-10))\n",
    "ridge_lambda.fit(Xstd, y)\n",
    "coefs_lambda = pd.Series(ridge_lambda.coef_, index = X.columns)\n",
    "coefs_lambda.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "587f9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "st_logg           -1.270665\n",
       "sy_pnum           -0.888378\n",
       "disc_year         -0.717445\n",
       "st_lum            -0.696500\n",
       "st_rad            -0.522443\n",
       "pl_controv_flag   -0.209565\n",
       "cb_flag           -0.119854\n",
       "obm_flag          -0.081300\n",
       "pl_dens           -0.073497\n",
       "micro_flag         0.000000\n",
       "pul_flag           0.000000\n",
       "ima_flag           0.003664\n",
       "sy_snum            0.016748\n",
       "ptv_flag           0.123637\n",
       "ast_flag           0.166958\n",
       "etv_flag           0.223187\n",
       "ttv_flag           0.239778\n",
       "tran_flag          0.260198\n",
       "pl_orbper          0.608761\n",
       "st_teff            0.881772\n",
       "st_mass            1.051626\n",
       "rv_flag            3.456939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.Series(ridge.coef_, index = X.columns)\n",
    "coefs.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483159e",
   "metadata": {},
   "source": [
    "# Q2e {-}\n",
    "Why do you think the coefficients of the two variables indentified in the previous question shrunk the most?\n",
    "\n",
    "**Hint:** VIF!\n",
    "\n",
    "*(4 points for justification - including any code used)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01a4b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature            VIF\n",
      "0             const  293592.094382\n",
      "1           sy_snum       1.162755\n",
      "2           sy_pnum       1.146094\n",
      "3           cb_flag       2.058390\n",
      "4         disc_year       1.362591\n",
      "5           rv_flag       2.014735\n",
      "6          pul_flag            NaN\n",
      "7          ptv_flag       2.610996\n",
      "8         tran_flag       2.466560\n",
      "9          ast_flag       1.091332\n",
      "10         obm_flag       1.183595\n",
      "11       micro_flag            NaN\n",
      "12         etv_flag       7.440160\n",
      "13         ima_flag   37675.155715\n",
      "14  pl_controv_flag       1.698968\n",
      "15        pl_orbper   37683.517115\n",
      "16          pl_dens       1.017593\n",
      "17         ttv_flag       1.110245\n",
      "18          st_teff      13.944718\n",
      "19           st_rad       3.257504\n",
      "20          st_mass       4.139998\n",
      "21           st_lum      12.507339\n",
      "22          st_logg      10.421923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvsim\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1715: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "X = add_constant(X)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"feature\"] = X.columns\n",
    "# calculating VIF for each feature\n",
    "#vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "# for i in range(len(X.columns))]\n",
    "for i in range(len(X.columns)):\n",
    "    vif.loc[i,'VIF'] = variance_inflation_factor(X.values, i)\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6586fb",
   "metadata": {},
   "source": [
    "**Because these two variables have such an strong linear relationship, they would introduce colinearity issues into the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7b63e",
   "metadata": {},
   "source": [
    "# Q2f {-}\n",
    "Develop a lasso model to predict `pl_rade` using all the variables in *train_CompositePlanetarySystems.csv* except `pl_name`, `disc_facility` and `disc_locale`. What is the optimal value of the tuning parameter $\\lambda$?\n",
    "\n",
    "**Hint:** You may use the following grid of lambda values to find the optimal $\\lambda$: \n",
    "`alphas = 10**np.linspace(0,-2.5,200)*0.5`\n",
    "\n",
    "*(4 points for code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcfffa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002051329052913595"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = 10**np.linspace(0,-2.5,200)*0.5\n",
    "lassocv = LassoCV(alphas = alphas, cv = 10, max_iter = 100000)\n",
    "lassocv.fit(Xstd, y)\n",
    "\n",
    "#Optimal value of the tuning parameter - lamda\n",
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc7510",
   "metadata": {},
   "source": [
    "# Q2g {-}\n",
    "Use the optimal value of $\\lambda$ found in the previous question to develop a lasso model. What is the RMSE of the model on *test1_CompositePlanetarySystems.csv* and *test2_CompositePlanetarySystems.csv*?\n",
    "\n",
    "*(5 points for code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e25a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1 RMSE: 3.220582381965326\n",
      "test 2 RMSE: 202.66277572552613\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression - Test 1\n",
    "lasso = Lasso(alpha = lassocv.alpha_)\n",
    "lasso.fit(Xstd, y)\n",
    "pred=lasso.predict(Xtest1_std)\n",
    "rmse_1 = np.sqrt(((pred - test1.pl_rade)**2).mean())\n",
    "print('test 1 RMSE:', rmse_1)\n",
    "\n",
    "# Lasso Regression - Test 2\n",
    "pred=lasso.predict(Xtest2_std)\n",
    "rmse_2 = np.sqrt(((pred - test2.pl_rade)**2).mean())\n",
    "print('test 2 RMSE:', rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb70ff",
   "metadata": {},
   "source": [
    "# Q2h {-}\n",
    "Note that lasso has a much lower RMSE on test datasets as compared to Ordinary least squares (OLS) regression. Shrinking the coefficients has improved the model fit. Appreciate it. Which variables have been eliminated by lasso? \n",
    "\n",
    "To answer this question, find the predictors whose coefficients are 0 in the lasso model. \n",
    "\n",
    "*(2 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb543bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "micro_flag         0.000000\n",
       "ima_flag           0.000000\n",
       "pul_flag           0.000000\n",
       "sy_snum            0.012105\n",
       "pl_dens            0.071061\n",
       "obm_flag           0.083005\n",
       "ptv_flag           0.110936\n",
       "cb_flag            0.114719\n",
       "ast_flag           0.166013\n",
       "etv_flag           0.197494\n",
       "pl_controv_flag    0.215100\n",
       "ttv_flag           0.239185\n",
       "tran_flag          0.269474\n",
       "st_rad             0.524817\n",
       "pl_orbper          0.610153\n",
       "disc_year          0.717696\n",
       "st_lum             0.730514\n",
       "sy_pnum            0.888101\n",
       "st_teff            0.922826\n",
       "st_mass            1.051955\n",
       "st_logg            1.297343\n",
       "rv_flag            3.472807\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['pl_name', 'disc_facility', 'disc_locale', 'pl_rade'])\n",
    "np.abs((pd.Series(lasso.coef_, index = X.columns))).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2ae2d",
   "metadata": {},
   "source": [
    "**Ima_flag, micro_flag, and pul_flag were shrunk to 0 by the lasso.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
