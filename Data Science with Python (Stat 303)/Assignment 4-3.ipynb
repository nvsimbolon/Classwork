{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c54420b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494336de",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_train = pd.read_csv(\"house_price_train.csv\")\n",
    "price_test = pd.read_csv(\"house_price_test.csv\")\n",
    "feature_train = pd.read_csv(\"house_feature_train.csv\")\n",
    "feature_test = pd.read_csv(\"house_feature_test.csv\")\n",
    "\n",
    "train = pd.merge(price_train, feature_train)\n",
    "test = pd.merge(price_test, feature_test)\n",
    "\n",
    "X = train.drop(columns = ['house_price', 'house_id'])\n",
    "Xtest = test.drop(columns =  ['house_price', 'house_id'])\n",
    "y = train['house_price']\n",
    "ytest = test['house_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f34b7",
   "metadata": {},
   "source": [
    "# Q1 {-}\n",
    "Tune and develop the following models on the data *house_feature_train.csv* to predict *house_price*. Use all the predictors except *house_id*:\n",
    "\n",
    "a) Random forest (*you can pick up your tuned random forest model from assignment 3 - Q1b, don't need to re-tune it*) \\\n",
    "b) AdaBoost \\\n",
    "c) Gradient boost with *huber* loss \\\n",
    "d) XGBoost \\\n",
    "e) MARS\n",
    "\n",
    "Find the RMSE for each of the models on test data (*house_feature_test.csv*).\n",
    "\n",
    "*(5 points for tuning each model, 1 point for RMSE of each model - total 30 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04cf689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328.8766835818962"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=1,min_samples_leaf=3,min_samples_split=6,\n",
    "                        oob_score=True,n_jobs=-1, max_features=4).fit(X, y)\n",
    "#RMSE on test data\n",
    "pred = model.predict(Xtest)\n",
    "np.sqrt(mean_squared_error(test.house_price, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed82753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -270700.669349 using {'base_estimator': DecisionTreeRegressor(max_depth=5), 'learning_rate': 0.0001, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor(random_state=1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100,200]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "grid['base_estimator'] = [DecisionTreeRegressor(max_depth=3), DecisionTreeRegressor(max_depth=5), \n",
    "                          DecisionTreeRegressor(max_depth=10),DecisionTreeRegressor(max_depth=15)]\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='neg_mean_squared_error')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c32b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335.2751478786161"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoost Model\n",
    "model = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=5),n_estimators=200,learning_rate=0.0001,random_state=1).fit(X,y)\n",
    "\n",
    "#RMSE on test data\n",
    "pred = model.predict(Xtest)\n",
    "np.sqrt(mean_squared_error(test.house_price, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da8236b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5981a255b035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# execute the grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# summarize the best score and configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best: %f using %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=1,loss='huber')\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100,200,500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "grid['max_depth'] = [3,5,8,10,12,15]\n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='neg_mean_squared_error')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (np.sqrt(-grid_result.best_score_), grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e55862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358.3355886973277"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boost with Huber Loss Model\n",
    "model = GradientBoostingRegressor(max_depth=3,n_estimators=100,learning_rate=0.1, random_state=1,loss='huber').fit(X,y)\n",
    "\n",
    "#RMSE on test data\n",
    "pred = model.predict(Xtest)\n",
    "np.sqrt(mean_squared_error(test.house_price, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dcc57bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Optimal parameter values = {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250, 'reg_lambda': 0.01}\n",
      "Optimal cross validation R-squared =  0.7159891687438152\n"
     ]
    }
   ],
   "source": [
    "#K-fold cross validation to find optimal parameters for XGBoost\n",
    "param_grid = {'max_depth': [5,6,7],\n",
    "              'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "               'reg_lambda':[0,0.01,0.001],\n",
    "                'n_estimators':[150,175,250,500,1000]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state=1),                                                       \n",
    "                             param_grid = param_grid,                             \n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv)\n",
    "optimal_params.fit(X,y)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation R-squared = \",optimal_params.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5c235a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325.40441816082824"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Model\n",
    "model = xgb.XGBRegressor(random_state=1,max_depth=5,n_estimators=250,\n",
    "                                         learning_rate = 0.01,reg_lambda=0.01)\n",
    "model.fit(X,y)\n",
    "np.sqrt(mean_squared_error(model.predict(Xtest),ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "511e214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 387.6692610337935,\n",
       " 2: 388.9160524789007,\n",
       " 3: 388.4535600285385,\n",
       " 4: 421.7251605168303,\n",
       " 5: 406.09330716015495,\n",
       " 6: 384.5930202801327,\n",
       " 7: 384.5930202801327,\n",
       " 8: 384.5930202801327,\n",
       " 9: 384.5930202801327,\n",
       " 10: 384.5930202801327,\n",
       " 11: 384.5930202801327,\n",
       " 12: 384.5930202801327,\n",
       " 13: 384.5930202801327,\n",
       " 14: 384.5930202801327,\n",
       " 15: 384.5930202801327,\n",
       " 16: 384.5930202801327,\n",
       " 17: 384.5930202801327,\n",
       " 18: 384.5930202801327,\n",
       " 19: 384.5930202801327}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = {}\n",
    "for i in range(1,20):\n",
    "    model = Earth(max_terms=500, max_degree=i)\n",
    "    model.fit(X,y)\n",
    "    n[i] = np.sqrt(mean_squared_error(model.predict(Xtest),ytest))\n",
    "    \n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "845562a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384.5930202801327"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MARS Model\n",
    "model = Earth(max_terms=500, max_degree=6) # note, terms in brackets are the hyperparameters \n",
    "model.fit(X,y)\n",
    "\n",
    "pred = model.predict(Xtest)\n",
    "np.sqrt(mean_squared_error(test.house_price, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09436d",
   "metadata": {},
   "source": [
    "# Q2 {-}\n",
    "Use the following ensembling methods to create an ensemble models based on all the tuned models from *Q1*:\n",
    "\n",
    "a) Voting ensemble *(5 points for code, 1 point for RMSE)* \\\n",
    "b) Stacking ensemble *(5 points for code, 1 point for RMSE)*\n",
    "\n",
    "Find the RMSE of each of the ensemble models on test data (*house_feature_test.csv*). \n",
    "\n",
    "The RMSEs of both the ensemble models are likely to be lower than the RMSEs of each of the individual models in *Q1*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a06e3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble Model RMSE =  313.2734963193911\n"
     ]
    }
   ],
   "source": [
    "#Voting Ensemble\n",
    "m1 = xgb.XGBRegressor(random_state=1,max_depth=5,n_estimators=250,\n",
    "                                         learning_rate = 0.01,reg_lambda=0.01)\n",
    "\n",
    "m2 = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=5),n_estimators=200,learning_rate=0.0001,random_state=1).fit(X,y)\n",
    "\n",
    "m3 = RandomForestRegressor(n_estimators=100, random_state=1,min_samples_leaf=3,min_samples_split=6,\n",
    "                        oob_score=True,n_jobs=-1, max_features=4).fit(X, y)\n",
    "\n",
    "m4 = GradientBoostingRegressor(max_depth=3,n_estimators=100,learning_rate=0.1, random_state=1,loss='huber').fit(X,y)\n",
    "\n",
    "m5 = Earth(max_terms=500, max_degree=6)\n",
    "\n",
    "en=VotingRegressor(estimators = [('xgb',m1),('ada',m2),('rf',m3),('gb',m4), ('mars', m5)])\n",
    "en.fit(X,y)\n",
    "print(\"Voting Ensemble Model RMSE = \", np.sqrt(mean_squared_error(en.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "172bde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Model RMSE =  320.14455366735916\n"
     ]
    }
   ],
   "source": [
    "# Stacking Ensemble\n",
    "en=StackingRegressor(estimators = [('xgb',m1),('ada',m2),('rf',m3),('gb',m4), ('mars', m5)],\n",
    "                     final_estimator=LinearRegression(),                                          \n",
    "                    cv = KFold(n_splits = 5, shuffle = True, random_state=1))\n",
    "en.fit(X,y)\n",
    "print(\"Stacking Ensemble Model RMSE = \", np.sqrt(mean_squared_error(en.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373db9f",
   "metadata": {},
   "source": [
    "# Q3 {-}\n",
    "Which are the most important and the least important models in the stacked ensemble model developed in *Q2(b)*? \n",
    "\n",
    "*(2 points for code, 1 point for answer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1851ea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05826766, 0.21547914, 0.47445034, 0.19809522, 0.05277925])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ece6b",
   "metadata": {},
   "source": [
    "The stacked ensemble model gives the highest weight to the random forest regressor model, and the lowest weight to the MARS model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
